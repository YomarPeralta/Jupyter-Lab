{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TecnicaANN_Proyecto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YomarPeralta/Jupyter-Lab/blob/main/TecnicaANN_Proyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjBpw91-WIUt",
        "outputId": "02086c0e-3b91-4e57-e54a-258215d926c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    locationId parameter      value\n",
            "0        42641      pm25  11.270000\n",
            "1        42641       no2  64.400722\n",
            "2        42644      pm25   9.436000\n",
            "3        42643        co   0.669755\n",
            "4        42645       no2   8.221209\n",
            "5        42647      pm25   0.000000\n",
            "6        42643      pm25  29.289000\n",
            "7        42646       no2  41.346738\n",
            "8        42642        co   0.658695\n",
            "9        42644       no2  43.539311\n",
            "10       42648       so2   4.675383\n",
            "11       42643       no2   5.483313\n",
            "12       42647      pm10   0.000000\n",
            "13       42642       so2   5.279586\n",
            "14       42641       so2   5.098069\n",
            "[[4.26410000e+04 1.12700000e+01]\n",
            " [4.26410000e+04 6.44007225e+01]\n",
            " [4.26440000e+04 9.43600000e+00]\n",
            " ...\n",
            " [4.26480000e+04 5.61470737e+00]\n",
            " [4.26480000e+04 2.63464388e-01]\n",
            " [4.26440000e+04 2.17630000e+01]]\n",
            "[['no2' 64.40072245176]\n",
            " ['pm25' 9.436]\n",
            " ['co' 0.669755051]\n",
            " ['no2' 8.22120878764]\n",
            " ['pm25' 0.0]\n",
            " ['pm25' 29.289]\n",
            " ['no2' 41.34673806556]\n",
            " ['co' 0.658695317]\n",
            " ['no2' 43.53931113198]\n",
            " ['so2' 4.675383412364]\n",
            " ['no2' 5.48331308892]\n",
            " ['pm10' 0.0]\n",
            " ['so2' 5.279586162628]\n",
            " ['so2' 5.098068720276]]\n",
            "[[1 64.40072245176]\n",
            " [3 9.436]\n",
            " [0 0.669755051]\n",
            " [1 8.22120878764]\n",
            " [3 0.0]\n",
            " [3 29.289]\n",
            " [1 41.34673806556]\n",
            " [0 0.658695317]\n",
            " [1 43.53931113198]\n",
            " [4 4.675383412364]\n",
            " [1 5.48331308892]\n",
            " [2 0.0]\n",
            " [4 5.279586162628]\n",
            " [4 5.098068720276]]\n",
            "[[0.0 1.0 0.0 0.0 0.0 64.40072245176]\n",
            " [0.0 0.0 0.0 1.0 0.0 9.436]\n",
            " [1.0 0.0 0.0 0.0 0.0 0.669755051]\n",
            " [0.0 1.0 0.0 0.0 0.0 8.22120878764]\n",
            " [0.0 0.0 0.0 1.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0 29.289]\n",
            " [0.0 1.0 0.0 0.0 0.0 41.34673806556]\n",
            " [1.0 0.0 0.0 0.0 0.0 0.658695317]\n",
            " [0.0 1.0 0.0 0.0 0.0 43.53931113198]\n",
            " [0.0 0.0 0.0 0.0 1.0 4.675383412364]\n",
            " [0.0 1.0 0.0 0.0 0.0 5.48331308892]\n",
            " [0.0 0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 0.0 1.0 5.279586162628]\n",
            " [0.0 0.0 0.0 0.0 1.0 5.098068720276]]\n",
            "[[0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0]\n",
            " [1.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [1.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 0.0 1.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 1.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 0.0 1.0]\n",
            " [0.0 0.0 0.0 0.0 1.0]]\n"
          ]
        }
      ],
      "source": [
        "''' Importacion de los paquetes y librerias necesarias para crear la Tecnica ANN '''\n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "''' Carga del dataset del proyecto'''\n",
        "filename = \"Dataset_Aire_14197.csv\"\n",
        "data = pandas.read_csv(filename, header=0)\n",
        "#print(data.head(100))\n",
        "#trainy=data['locationId']\n",
        "#print(trainy.head(100))\n",
        "''' Eliminacion de las columnas que son innecesarias para la creacion del modelo'''\n",
        "data_sc=data.drop(\"country\",axis=1)\n",
        "data_sc=data_sc.drop(\"utc\",axis=1)\n",
        "data_sc=data_sc.drop(\"location\",axis=1)\n",
        "data_sc=data_sc.drop(\"city\",axis=1)\n",
        "data_sc=data_sc.drop(\"unit\",axis=1)\n",
        "data_sc=data_sc.drop(\"latitude\",axis=1)\n",
        "data_sc=data_sc.drop(\"longitude\",axis=1)\n",
        "data_sc=data_sc.drop(\"local\",axis=1)\n",
        "''' Definicion de la impresion de 15 datos de las X y Y '''\n",
        "print(data_sc.head(15))\n",
        "X = data_sc.iloc[:, [0,2]].values\n",
        "print(X)\n",
        "Y = data_sc.iloc[:,[1,2] ].values\n",
        "print(Y[1:15:])\n",
        "labelencoder_X2 = LabelEncoder()\n",
        "Y[:,0] = labelencoder_X2.fit_transform(Y[:,0])\n",
        "print(Y[1:15:])\n",
        "''' Importacion de los paquetes OneHotEncoder y ColumnTransformer para poder realizar el preprocesamiento de los datos '''\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "''' Creacion de la funcion de transformacion '''\n",
        "transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"Churn_Modelling\",        # Un nombre de la transformaci√≥n\n",
        "         OneHotEncoder(categories='auto'), # La clase a la que transformar\n",
        "         [0]            # Las columnas a transformar.\n",
        "         )\n",
        "    ], remainder='passthrough'\n",
        ")\n",
        "''' Definicion de la variable de salida, nuestra Y \n",
        "con los respectivos parametros que se requieren '''\n",
        "Y = transformer.fit_transform(Y)\n",
        "print(Y[1:15:])\n",
        "Y=Y[:,0:5]\n",
        "print(Y[1:15:])\n",
        "''' Importacion del paquete Train Test Split '''\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)\n",
        "''' Importacion del paquete StandarScaler con la definicion \n",
        "asi mismo de los datos que se trabajaron en el split, y tambien las entradas de entrenamiento y evaluacion '''\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sX = StandardScaler()\n",
        "X_train = sX.fit_transform(X_train)\n",
        "X_test = sX.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#construimos nuestra red neuronal\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "clf = Sequential()\n",
        "\n",
        "#primera capa\n",
        "clf.add(Dense(units = 6,kernel_initializer = \"uniform\", activation = \"relu\", input_dim = 2))\n",
        "clf.add(Dropout(0.1))\n",
        "\n",
        "#segunda capa\n",
        "clf.add(Dense(units = 6,kernel_initializer = \"uniform\", activation = \"relu\"))\n",
        "clf.add(Dropout(0.1))\n",
        "\n",
        "#segunda capa\n",
        "clf.add(Dense(units = 5,kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
        "\n",
        "''' Compilacion de todas las capas con su accuracy '''\n",
        "clf.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "''' Cambio del tipo de dato que se estan trabajando a tipo float para poder trabajarlos '''\n",
        "X_train = np.asarray(X_train).astype(np.float32)\n",
        "Y_train = np.asarray(Y_train).astype(np.float32)\n",
        "clf.fit(X_train, Y_train, batch_size = 10, epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GC_dpDx1CVl",
        "outputId": "c79224ec-35cc-4602-b123-fd10218091d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1136/1136 [==============================] - 3s 2ms/step - loss: 0.4646 - accuracy: 0.3317\n",
            "Epoch 2/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3942 - accuracy: 0.5007\n",
            "Epoch 3/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3448 - accuracy: 0.6194\n",
            "Epoch 4/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.3101 - accuracy: 0.6608\n",
            "Epoch 5/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2952 - accuracy: 0.6723\n",
            "Epoch 6/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.6919\n",
            "Epoch 7/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2734 - accuracy: 0.6977\n",
            "Epoch 8/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2679 - accuracy: 0.7049\n",
            "Epoch 9/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2646 - accuracy: 0.7062\n",
            "Epoch 10/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2625 - accuracy: 0.7079\n",
            "Epoch 11/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2622 - accuracy: 0.7091\n",
            "Epoch 12/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2604 - accuracy: 0.7100\n",
            "Epoch 13/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2585 - accuracy: 0.7142\n",
            "Epoch 14/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2593 - accuracy: 0.7143\n",
            "Epoch 15/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2587 - accuracy: 0.7146\n",
            "Epoch 16/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2590 - accuracy: 0.7133\n",
            "Epoch 17/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2565 - accuracy: 0.7157\n",
            "Epoch 18/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2576 - accuracy: 0.7137\n",
            "Epoch 19/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2570 - accuracy: 0.7137\n",
            "Epoch 20/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2569 - accuracy: 0.7176\n",
            "Epoch 21/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2558 - accuracy: 0.7152\n",
            "Epoch 22/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2564 - accuracy: 0.7192\n",
            "Epoch 23/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2548 - accuracy: 0.7174\n",
            "Epoch 24/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2548 - accuracy: 0.7191\n",
            "Epoch 25/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2550 - accuracy: 0.7181\n",
            "Epoch 26/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2559 - accuracy: 0.7173\n",
            "Epoch 27/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2545 - accuracy: 0.7200\n",
            "Epoch 28/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2543 - accuracy: 0.7212\n",
            "Epoch 29/50\n",
            "1136/1136 [==============================] - 3s 2ms/step - loss: 0.2553 - accuracy: 0.7159\n",
            "Epoch 30/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2539 - accuracy: 0.7208\n",
            "Epoch 31/50\n",
            "1136/1136 [==============================] - 2s 1ms/step - loss: 0.2549 - accuracy: 0.7150\n",
            "Epoch 32/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2545 - accuracy: 0.7143\n",
            "Epoch 33/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2524 - accuracy: 0.7207\n",
            "Epoch 34/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2528 - accuracy: 0.7183\n",
            "Epoch 35/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2548 - accuracy: 0.7138\n",
            "Epoch 36/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2522 - accuracy: 0.7176\n",
            "Epoch 37/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2537 - accuracy: 0.7164\n",
            "Epoch 38/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2521 - accuracy: 0.7201\n",
            "Epoch 39/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2532 - accuracy: 0.7163\n",
            "Epoch 40/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2530 - accuracy: 0.7195\n",
            "Epoch 41/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2538 - accuracy: 0.7128\n",
            "Epoch 42/50\n",
            "1136/1136 [==============================] - 2s 1ms/step - loss: 0.2531 - accuracy: 0.7174\n",
            "Epoch 43/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2530 - accuracy: 0.7129\n",
            "Epoch 44/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2524 - accuracy: 0.7179\n",
            "Epoch 45/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2499 - accuracy: 0.7213\n",
            "Epoch 46/50\n",
            "1136/1136 [==============================] - 2s 1ms/step - loss: 0.2528 - accuracy: 0.7156\n",
            "Epoch 47/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2537 - accuracy: 0.7143\n",
            "Epoch 48/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2519 - accuracy: 0.7189\n",
            "Epoch 49/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2509 - accuracy: 0.7193\n",
            "Epoch 50/50\n",
            "1136/1136 [==============================] - 2s 2ms/step - loss: 0.2523 - accuracy: 0.7159\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01fc77e410>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.asarray(X_test).astype(np.float32)\n",
        "Y_test = np.asarray(Y_test).astype(np.float32)\n",
        "accuracy=clf.evaluate(X_test,Y_test)\n",
        "print(accuracy)\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred = np.asarray(y_pred).astype(np.float32)\n",
        "y_pred=np.round(y_pred)\n",
        "print(y_pred[0:15,])\n",
        "print(Y_test[0:15,])\n",
        "y_test = []\n",
        "Y_pred = []\n",
        "for x in Y_test:\n",
        "  if(x[0]==1 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    y_test.append('pm25')\n",
        "  if(x[0]==0 and x[1]==1 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    y_test.append('no2')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==1 and x[3]==0 and x[4]==0):\n",
        "    y_test.append('pm10')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==1 and x[4]==0):\n",
        "    y_test.append('co')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==1):\n",
        "    y_test.append('so2')\n",
        "for x in y_pred:\n",
        "  if(x[0]==1 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    Y_pred.append('pm25')\n",
        "  if(x[0]==0 and x[1]==1 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    Y_pred.append('no2')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==1 and x[3]==0 and x[4]==0):\n",
        "    Y_pred.append('pm10')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==1 and x[4]==0):\n",
        "    Y_pred.append('co')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==1):\n",
        "    Y_pred.append('so2')\n",
        "print(Y_pred[0:15])\n",
        "print(y_test[0:15])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYvBcgEIriUR",
        "outputId": "85927098-840a-4e09-e0d8-96532ae99f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.7521\n",
            "[0.23534387350082397, 0.7521126866340637]\n",
            "[[0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n",
            "[[0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n",
            "['co', 'pm25', 'so2', 'pm25', 'pm25', 'co', 'so2', 'so2', 'so2', 'co', 'so2', 'pm25', 'so2', 'pm25', 'so2']\n",
            "['co', 'pm25', 'so2', 'pm25', 'pm25', 'co', 'so2', 'co', 'so2', 'co', 'co', 'so2', 'co', 'pm25', 'so2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# create a confusion matrix to visually represent incorrectly classified images\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, out_path=\"\"):\n",
        "    cm = confusion_matrix(y_true, y_pred,normalize=\"true\")\n",
        "    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    ax = sn.heatmap(df_cm, annot=True, square=True, linewidths=.2,cmap=\"YlGnBu\" ,cbar_kws={\"shrink\": 0.8})\n",
        "    return ax"
      ],
      "metadata": {
        "id": "PxI5cWjceaii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(X_test)\n",
        "labels=['pm25','no2','pm10','co','so2']\n",
        "plot_confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1),labels)"
      ],
      "metadata": {
        "id": "xkflXyJLefHC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}